# Health-Care-Analysis
# HDFS-and-Hive

# Description of Project

For this Big-data project, I took the Health-Care data from Kaggle website, and converted that data into CSV file. The dataset contains 12 columns and 5111 rows approximately. Then using Ambari I imported the CSV file data into HDFS. After that I created one database and table inside that database using Hive. Then I loaded the data into the Hive table and finally did some analysis on that dataset with the help of Hive queries. And also stored the output of Hive queries back into HDFS.

# Objective

The main aim of this project is to analyze the data of patients who are facing problems with Hypertension,Heart Disease and Stroke.


# Technologies Used

**HDFS:** For storing large web-series dataset and provides easier access to hive tables.

**Hive:** Hive is used  to facilitates easy data summarization, ad-hoc queries, and the analysis of web-seires datasets stored in Hadoop compatible file systems.

# Features

* Created a table in hive using HiveQL create command and loaded the data into a Hive table.
* Did some analysis on that dataset with the help of Hive queries.
* Stored output of Hive queries into a file in HDFS.
* Applied Partitioning and Bucketing concepts in Hive.

# References

* https://www.tutorialspoint.com/hive/hive_create_table.htm
* https://www.geeksforgeeks.org/hive-load-data-into-table/
* https://sparkbyexamples.com/apache-hive/hive-partitioning-vs-bucketing-with-examples/

